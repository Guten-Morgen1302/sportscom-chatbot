{"file_contents":{"app.py":{"content":"from flask import Flask, request, jsonify, render_template_string\nfrom flask_cors import CORS\nimport re\nimport os\nfrom dotenv import load_dotenv\nimport google.generativeai as genai\nimport hashlib\nfrom collections import Counter\n\nload_dotenv()\n\napp = Flask(__name__)\nCORS(app)\n\n# Load system prompt\nwith open(\"system_prompt.txt\", \"r\", encoding=\"utf-8\") as f:\n    SYSTEM_PROMPT = f.read()\n\n# Load chat data\nwith open(\"processed_chunks.txt\", \"r\", encoding=\"utf-8\") as f:\n    chat_data = f.read()\n\n# Initialize Gemini\ngenai.configure(api_key=os.environ.get(\"GEMINI_API_KEY\"))\nmodel = genai.GenerativeModel('gemini-2.5-flash')\n\n# Split into chunks for easier searching\nchunks = [chunk.strip() for chunk in chat_data.split('\\n\\n') if chunk.strip()]\n\n# Create simple embeddings using TF-IDF like approach\ndef create_text_fingerprint(text):\n    \"\"\"Create a simple text fingerprint using word frequency and patterns\"\"\"\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n    word_counts = Counter(words)\n    # Create a hash-based fingerprint\n    fingerprint = {}\n    for word, count in word_counts.most_common(50):  # Top 50 words\n        fingerprint[word] = count\n    return fingerprint\n\n# Pre-compute fingerprints for all chunks\nchunk_fingerprints = [create_text_fingerprint(chunk) for chunk in chunks]\n\ndef compute_similarity_score(fingerprint1, fingerprint2):\n    \"\"\"Compute similarity between two text fingerprints\"\"\"\n    common_words = set(fingerprint1.keys()).intersection(set(fingerprint2.keys()))\n    if not common_words:\n        return 0.0\n    \n    score = 0.0\n    total_weight = 0.0\n    \n    for word in common_words:\n        # Weight by frequency in both texts\n        weight = min(fingerprint1[word], fingerprint2[word])\n        score += weight\n        total_weight += weight\n    \n    # Normalize by total words in query\n    query_total = sum(fingerprint1.values())\n    return score / max(query_total, 1) if query_total > 0 else 0.0\n\ndef find_relevant_context(user_message):\n    \"\"\"\n    Find relevant context using improved semantic similarity\n    \"\"\"\n    user_fingerprint = create_text_fingerprint(user_message)\n    chunk_scores = []\n    \n    # Compute similarity scores for all chunks\n    for i, chunk_fingerprint in enumerate(chunk_fingerprints):\n        similarity = compute_similarity_score(user_fingerprint, chunk_fingerprint)\n        if similarity > 0.1:  # Minimum similarity threshold\n            chunk_scores.append((similarity, i, chunks[i]))\n    \n    # Sort by similarity score and return top matches\n    chunk_scores.sort(reverse=True, key=lambda x: x[0])\n    return [chunk for _, _, chunk in chunk_scores[:3]]\n\ndef validate_response_rules(response, user_message):\n    \"\"\"Validate response follows system prompt rules\"\"\"\n    user_lower = user_message.lower()\n    response_lower = response.lower()\n    \n    # Check event isolation rules\n    events = {'agility', 'spoorthi', 'marathon'}\n    user_event = None\n    for event in events:\n        if event in user_lower:\n            user_event = event\n            break\n    \n    if user_event:\n        other_events = events - {user_event}\n        for other_event in other_events:\n            if other_event in response_lower:\n                return False, f\"Response mentions {other_event} when user asked about {user_event}\"\n    \n    # Check length limit (800 chars unless \"detail\" requested, then 1200 chars max)\n    if \"detail\" in user_lower:\n        if len(response) > 1200:\n            return False, \"Response exceeds 1200 character limit for detailed responses\"\n    else:\n        if len(response) > 800:\n            return False, \"Response exceeds 800 character limit\"\n    \n    return True, \"Valid\"\n\ndef query_gemini_model(user_message, context=None):\n    \"\"\"\n    Query Gemini model with proper safety checks\n    \"\"\"\n    api_key = os.environ.get(\"GEMINI_API_KEY\")\n    if not api_key:\n        return generate_fallback_response(user_message, context)\n    \n    try:\n        # Construct prompt with system instructions and context\n        if context:\n            context_text = \"\\n\".join(context)\n            prompt = f\"\"\"\n{SYSTEM_PROMPT}\n\nContext from SportsCom chat history:\n{context_text}\n\nUser: {user_message}\n\nRespond as a SPIT SportsCom senior student in Hinglish, following the rules strictly. Keep it under 800 characters unless user says \"detail\".\n\"\"\"\n        else:\n            prompt = f\"\"\"\n{SYSTEM_PROMPT}\n\nUser: {user_message}\n\nRespond as a SPIT SportsCom senior student in Hinglish. If you don't know, say \"Ask this on sports update group\".\n\"\"\"\n\n        # Configure safety settings\n        safety_settings = [\n            {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n            {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n            {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n            {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"}\n        ]\n        \n        # Generate response\n        response = model.generate_content(\n            prompt,\n            safety_settings=safety_settings,\n            generation_config=genai.GenerationConfig(\n                max_output_tokens=1000,\n                temperature=0.7,\n                top_k=40,\n                top_p=0.8,\n            )\n        )\n        \n        if response.text:\n            # Validate response follows rules\n            is_valid, validation_msg = validate_response_rules(response.text, user_message)\n            if is_valid:\n                return response.text\n            else:\n                print(f\"Response validation failed: {validation_msg}\")\n                return generate_fallback_response(user_message, context)\n        \n        return generate_fallback_response(user_message, context)\n        \n    except Exception as e:\n        print(f\"Error calling Gemini: {e}\")\n        return generate_fallback_response(user_message, context)\n\ndef generate_fallback_response(user_message, context):\n    \"\"\"\n    Generate fallback response when Gemini is not available\n    \"\"\"\n    user_message_lower = user_message.lower()\n    \n    # Basic rule-based responses based on system prompt\n    if any(word in user_message_lower for word in ['agility', 'cup']):\n        return \"Agility Cup open hai bro‚Äîapni team banao, mix branches/years chalega. November first week tentative hai. Final dates class groups pe aayenge.\"\n    \n    elif any(word in user_message_lower for word in ['spoorthi']):\n        return \"Spoorthi Feb-Mar mein hai. Team sports ke liye college team selection chahiye, chess/TT jaise solos jab announce honge tab.\"\n    \n    elif any(word in user_message_lower for word in ['committee', 'join', 'selection']):\n        return \"Committee selections after 10th October. Forms kal se float ho jayenge. Interview hogi but bakchodiyan bhi hongi, dw.\"\n    \n    elif any(word in user_message_lower for word in ['date', 'when', 'schedule']):\n        return \"Seniors will post the final dates on official class groups.\"\n    \n    elif any(word in user_message_lower for word in ['basketball']):\n        return \"Basketball trials early Oct. Venue: Wadia court.\"\n    \n    elif any(word in user_message_lower for word in ['cricket', 'football']):\n        return \"Cricket/Football trials tentatively 1st week Nov. Venue: Bhavan's ground (post-rains maintenance dependent).\"\n    \n    elif any(word in user_message_lower for word in ['badminton']):\n        return \"Badminton venue: ASC courts (online booking available).\"\n    \n    elif any(word in user_message_lower for word in ['chess']):\n        return \"FIDE Chess tournament bhi hai. Chess teams technical hai, practice groups banenge.\"\n    \n    elif any(word in user_message_lower for word in ['venue', 'where', 'court']):\n        return \"Basketball: Wadia court, Cricket/Football: Bhavan's ground, Badminton: ASC courts, TT/Carrom: Gymkhana.\"\n    \n    else:\n        return \"Ask this on sports update group.\"\n\n@app.route('/chat', methods=['POST'])\ndef chat():\n    try:\n        user_input = request.json.get(\"message\", \"\").strip()\n        \n        if not user_input:\n            return jsonify({\"response\": \"Kuch toh bolo yaar!\"})\n        \n        # Find relevant context\n        context = find_relevant_context(user_input)\n        \n        # Generate response\n        ai_response = query_gemini_model(user_input, context)\n        \n        return jsonify({\"response\": ai_response})\n        \n    except Exception as e:\n        print(f\"Error in chat endpoint: {e}\")\n        return jsonify({\"response\": \"Something went wrong. Ask this on sports update group.\"})\n\n@app.route('/')\ndef index():\n    try:\n        with open(\"static/index.html\", \"r\", encoding=\"utf-8\") as f:\n            html_content = f.read()\n        return html_content\n    except FileNotFoundError:\n        return jsonify({\"error\": \"Frontend not found\"}), 404\n\n@app.route('/health', methods=['GET'])\ndef health():\n    return jsonify({\"status\": \"ok\", \"message\": \"SPIT SportsCom Bot is running!\"})\n\nif __name__ == '__main__':\n    print(\"Starting SPIT SportsCom Bot...\")\n    app.run(debug=True, host='0.0.0.0', port=5000)","size_bytes":9079},"api/index.py":{"content":"from flask import Flask, request, jsonify\nfrom flask_cors import CORS\nimport re\nimport os\nfrom dotenv import load_dotenv\nimport google.generativeai as genai\nimport hashlib\nfrom collections import Counter\n\n# Load environment variables\nload_dotenv()\n\napp = Flask(__name__)\nCORS(app)\n\n# Load system prompt from root directory\ntry:\n    with open(\"../system_prompt.txt\", \"r\", encoding=\"utf-8\") as f:\n        SYSTEM_PROMPT = f.read()\nexcept FileNotFoundError:\n    with open(\"system_prompt.txt\", \"r\", encoding=\"utf-8\") as f:\n        SYSTEM_PROMPT = f.read()\n\n# Load chat data from root directory  \ntry:\n    with open(\"../processed_chunks.txt\", \"r\", encoding=\"utf-8\") as f:\n        chat_data = f.read()\nexcept FileNotFoundError:\n    with open(\"processed_chunks.txt\", \"r\", encoding=\"utf-8\") as f:\n        chat_data = f.read()\n\n# Initialize Gemini\napi_key = os.environ.get(\"GEMINI_API_KEY\")\nif api_key:\n    genai.configure(api_key=api_key)\n    model = genai.GenerativeModel('gemini-2.5-flash')\n\n# Split into chunks for easier searching\nchunks = [chunk.strip() for chunk in chat_data.split('\\n\\n') if chunk.strip()]\n\n# Create simple embeddings using TF-IDF like approach\ndef create_text_fingerprint(text):\n    \"\"\"Create a simple text fingerprint using word frequency and patterns\"\"\"\n    words = re.findall(r'\\b\\w+\\b', text.lower())\n    word_counts = Counter(words)\n    # Create a hash-based fingerprint\n    fingerprint = {}\n    for word, count in word_counts.most_common(50):  # Top 50 words\n        fingerprint[word] = count\n    return fingerprint\n\n# Pre-compute fingerprints for all chunks\nchunk_fingerprints = [create_text_fingerprint(chunk) for chunk in chunks]\n\ndef compute_similarity_score(fingerprint1, fingerprint2):\n    \"\"\"Compute similarity between two text fingerprints\"\"\"\n    common_words = set(fingerprint1.keys()).intersection(set(fingerprint2.keys()))\n    if not common_words:\n        return 0.0\n    \n    score = 0.0\n    total_weight = 0.0\n    \n    for word in common_words:\n        # Weight by frequency in both texts\n        weight = min(fingerprint1[word], fingerprint2[word])\n        score += weight\n        total_weight += weight\n    \n    # Normalize by total words in query\n    query_total = sum(fingerprint1.values())\n    return score / max(query_total, 1) if query_total > 0 else 0.0\n\ndef find_relevant_context(user_message):\n    \"\"\"Find relevant context using improved semantic similarity\"\"\"\n    user_fingerprint = create_text_fingerprint(user_message)\n    chunk_scores = []\n    \n    # Compute similarity scores for all chunks\n    for i, chunk_fingerprint in enumerate(chunk_fingerprints):\n        similarity = compute_similarity_score(user_fingerprint, chunk_fingerprint)\n        if similarity > 0.1:  # Minimum similarity threshold\n            chunk_scores.append((similarity, i, chunks[i]))\n    \n    # Sort by similarity score and return top matches\n    chunk_scores.sort(reverse=True, key=lambda x: x[0])\n    return [chunk for _, _, chunk in chunk_scores[:3]]\n\ndef validate_response_rules(response, user_message):\n    \"\"\"Validate response follows system prompt rules\"\"\"\n    user_lower = user_message.lower()\n    response_lower = response.lower()\n    \n    # Check event isolation rules\n    events = {'agility', 'spoorthi', 'marathon'}\n    user_event = None\n    for event in events:\n        if event in user_lower:\n            user_event = event\n            break\n    \n    if user_event:\n        other_events = events - {user_event}\n        for other_event in other_events:\n            if other_event in response_lower:\n                return False, f\"Response mentions {other_event} when user asked about {user_event}\"\n    \n    # Check length limit (800 chars unless \"detail\" requested, then 1200 chars max)\n    if \"detail\" in user_lower:\n        if len(response) > 1200:\n            return False, \"Response exceeds 1200 character limit for detailed responses\"\n    else:\n        if len(response) > 800:\n            return False, \"Response exceeds 800 character limit\"\n    \n    return True, \"Valid\"\n\ndef query_gemini_model(user_message, context=None):\n    \"\"\"Query Gemini model with proper safety checks\"\"\"\n    if not api_key:\n        return generate_fallback_response(user_message, context)\n    \n    try:\n        # Construct prompt with system instructions and context\n        if context:\n            context_text = \"\\n\".join(context)\n            prompt = f\"\"\"\n{SYSTEM_PROMPT}\n\nContext from SportsCom chat history:\n{context_text}\n\nUser: {user_message}\n\nRespond as a SPIT SportsCom senior student in Hinglish, following the rules strictly. Keep it under 800 characters unless user says \"detail\".\n\"\"\"\n        else:\n            prompt = f\"\"\"\n{SYSTEM_PROMPT}\n\nUser: {user_message}\n\nRespond as a SPIT SportsCom senior student in Hinglish. If you don't know, say \"Ask this on sports update group\".\n\"\"\"\n\n        # Configure safety settings\n        safety_settings = [\n            {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n            {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n            {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n            {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"}\n        ]\n        \n        # Generate response\n        response = model.generate_content(\n            prompt,\n            safety_settings=safety_settings,\n            generation_config=genai.GenerationConfig(\n                max_output_tokens=1000,\n                temperature=0.7,\n                top_k=40,\n                top_p=0.8,\n            )\n        )\n        \n        if response.text:\n            # Validate response follows rules\n            is_valid, validation_msg = validate_response_rules(response.text, user_message)\n            if is_valid:\n                return response.text\n            else:\n                print(f\"Response validation failed: {validation_msg}\")\n                return generate_fallback_response(user_message, context)\n        \n        return generate_fallback_response(user_message, context)\n        \n    except Exception as e:\n        print(f\"Error calling Gemini: {e}\")\n        return generate_fallback_response(user_message, context)\n\ndef generate_fallback_response(user_message, context):\n    \"\"\"Generate fallback response when Gemini is not available\"\"\"\n    user_message_lower = user_message.lower()\n    \n    # Basic rule-based responses based on system prompt\n    if any(word in user_message_lower for word in ['agility', 'cup']):\n        return \"Agility Cup open hai bro‚Äîapni team banao, mix branches/years chalega. November first week tentative hai. Final dates class groups pe aayenge.\"\n    \n    elif any(word in user_message_lower for word in ['spoorthi']):\n        return \"Spoorthi Feb-Mar mein hai. Team sports ke liye college team selection chahiye, chess/TT jaise solos jab announce honge tab.\"\n    \n    elif any(word in user_message_lower for word in ['committee', 'join', 'selection']):\n        return \"Committee selections after 10th October. Forms kal se float ho jayenge. Interview hogi but bakchodiyan bhi hongi, dw.\"\n    \n    elif any(word in user_message_lower for word in ['date', 'when', 'schedule']):\n        return \"Seniors will post the final dates on official class groups.\"\n    \n    elif any(word in user_message_lower for word in ['basketball']):\n        return \"Basketball trials early Oct. Venue: Wadia court.\"\n    \n    elif any(word in user_message_lower for word in ['cricket', 'football']):\n        return \"Cricket/Football trials tentatively 1st week Nov. Venue: Bhavan's ground (post-rains maintenance dependent).\"\n    \n    elif any(word in user_message_lower for word in ['badminton']):\n        return \"Badminton venue: ASC courts (online booking available).\"\n    \n    elif any(word in user_message_lower for word in ['chess']):\n        return \"FIDE Chess tournament bhi hai. Chess teams technical hai, practice groups banenge.\"\n    \n    elif any(word in user_message_lower for word in ['venue', 'where', 'court']):\n        return \"Basketball: Wadia court, Cricket/Football: Bhavan's ground, Badminton: ASC courts, TT/Carrom: Gymkhana.\"\n    \n    else:\n        return \"Ask this on sports update group.\"\n\n# Serve the frontend\n@app.route('/')\ndef index():\n    \"\"\"Serve the chat interface\"\"\"\n    html_content = \"\"\"<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>SPIT SportsCom Bot</title>\n    <style>\n        * {\n            margin: 0;\n            padding: 0;\n            box-sizing: border-box;\n        }\n        \n        body {\n            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n            height: 100vh;\n            display: flex;\n            justify-content: center;\n            align-items: center;\n        }\n        \n        .chat-container {\n            background: white;\n            border-radius: 15px;\n            box-shadow: 0 20px 40px rgba(0,0,0,0.1);\n            width: 90%;\n            max-width: 600px;\n            height: 80vh;\n            display: flex;\n            flex-direction: column;\n            overflow: hidden;\n        }\n        \n        .chat-header {\n            background: linear-gradient(135deg, #ff6b6b, #ee5a24);\n            color: white;\n            padding: 20px;\n            text-align: center;\n        }\n        \n        .chat-header h1 {\n            font-size: 24px;\n            margin-bottom: 5px;\n        }\n        \n        .chat-header p {\n            font-size: 14px;\n            opacity: 0.9;\n        }\n        \n        .chat-messages {\n            flex: 1;\n            padding: 20px;\n            overflow-y: auto;\n            background-color: #f8f9fa;\n        }\n        \n        .message {\n            margin-bottom: 15px;\n            padding: 12px 16px;\n            border-radius: 20px;\n            max-width: 80%;\n            word-wrap: break-word;\n            animation: fadeIn 0.3s ease-in;\n        }\n        \n        .user-message {\n            background: #007bff;\n            color: white;\n            margin-left: auto;\n            text-align: right;\n        }\n        \n        .bot-message {\n            background: white;\n            color: #333;\n            border: 2px solid #e9ecef;\n            margin-right: auto;\n        }\n        \n        .chat-input {\n            padding: 20px;\n            background: white;\n            border-top: 1px solid #e9ecef;\n            display: flex;\n            gap: 10px;\n        }\n        \n        .chat-input input {\n            flex: 1;\n            padding: 12px 16px;\n            border: 2px solid #e9ecef;\n            border-radius: 25px;\n            outline: none;\n            font-size: 16px;\n        }\n        \n        .chat-input input:focus {\n            border-color: #007bff;\n        }\n        \n        .chat-input button {\n            background: #007bff;\n            color: white;\n            border: none;\n            padding: 12px 20px;\n            border-radius: 25px;\n            cursor: pointer;\n            font-size: 16px;\n            transition: background 0.3s;\n        }\n        \n        .chat-input button:hover {\n            background: #0056b3;\n        }\n        \n        .chat-input button:disabled {\n            background: #6c757d;\n            cursor: not-allowed;\n        }\n        \n        @keyframes fadeIn {\n            from { opacity: 0; transform: translateY(10px); }\n            to { opacity: 1; transform: translateY(0); }\n        }\n        \n        .typing-indicator {\n            display: none;\n            padding: 12px 16px;\n            border-radius: 20px;\n            background: white;\n            border: 2px solid #e9ecef;\n            margin-right: auto;\n            max-width: 80%;\n            margin-bottom: 15px;\n        }\n        \n        .typing-dots {\n            display: flex;\n            gap: 4px;\n        }\n        \n        .typing-dots span {\n            width: 8px;\n            height: 8px;\n            background: #999;\n            border-radius: 50%;\n            animation: typing 1.4s infinite ease-in-out;\n        }\n        \n        .typing-dots span:nth-child(1) { animation-delay: -0.32s; }\n        .typing-dots span:nth-child(2) { animation-delay: -0.16s; }\n        \n        @keyframes typing {\n            0%, 80%, 100% { transform: scale(0.8); opacity: 0.5; }\n            40% { transform: scale(1); opacity: 1; }\n        }\n    </style>\n</head>\n<body>\n    <div class=\"chat-container\">\n        <div class=\"chat-header\">\n            <h1>üèè SPIT SportsCom Bot</h1>\n            <p>Tumhara senior sports committee member - Ask anything about SPIT sports!</p>\n        </div>\n        \n        <div class=\"chat-messages\" id=\"chatMessages\">\n            <div class=\"message bot-message\">\n                Hey! Main tumhara SportsCom senior hun. Kuch bhi poocho sports events, committees, trials ke baare mein. Agility Cup, Spoorthi, trials - sab kuch jaanta hun! üî•\n            </div>\n        </div>\n        \n        <div class=\"typing-indicator\" id=\"typingIndicator\">\n            <div class=\"typing-dots\">\n                <span></span>\n                <span></span>\n                <span></span>\n            </div>\n        </div>\n        \n        <div class=\"chat-input\">\n            <input type=\"text\" id=\"messageInput\" placeholder=\"Type your message here... (in Hinglish!)\" />\n            <button onclick=\"sendMessage()\" id=\"sendButton\">Send</button>\n        </div>\n    </div>\n\n    <script>\n        const chatMessages = document.getElementById('chatMessages');\n        const messageInput = document.getElementById('messageInput');\n        const sendButton = document.getElementById('sendButton');\n        const typingIndicator = document.getElementById('typingIndicator');\n\n        messageInput.addEventListener('keypress', function(e) {\n            if (e.key === 'Enter') {\n                sendMessage();\n            }\n        });\n\n        function addMessage(message, isUser) {\n            const messageDiv = document.createElement('div');\n            messageDiv.className = `message ${isUser ? 'user-message' : 'bot-message'}`;\n            messageDiv.textContent = message;\n            chatMessages.appendChild(messageDiv);\n            chatMessages.scrollTop = chatMessages.scrollHeight;\n        }\n\n        function showTyping() {\n            typingIndicator.style.display = 'block';\n            chatMessages.scrollTop = chatMessages.scrollHeight;\n        }\n\n        function hideTyping() {\n            typingIndicator.style.display = 'none';\n        }\n\n        async function sendMessage() {\n            const message = messageInput.value.trim();\n            if (!message) return;\n\n            // Disable input while processing\n            messageInput.disabled = true;\n            sendButton.disabled = true;\n\n            // Add user message\n            addMessage(message, true);\n            messageInput.value = '';\n\n            // Show typing indicator\n            showTyping();\n\n            try {\n                const response = await fetch('/chat', {\n                    method: 'POST',\n                    headers: {\n                        'Content-Type': 'application/json',\n                    },\n                    body: JSON.stringify({ message: message }),\n                });\n\n                const data = await response.json();\n                \n                // Hide typing indicator\n                hideTyping();\n                \n                // Add bot response\n                addMessage(data.response || 'Something went wrong!', false);\n\n            } catch (error) {\n                hideTyping();\n                addMessage('Sorry, something went wrong! Ask this on sports update group.', false);\n                console.error('Error:', error);\n            }\n\n            // Re-enable input\n            messageInput.disabled = false;\n            sendButton.disabled = false;\n            messageInput.focus();\n        }\n\n        // Focus on input when page loads\n        messageInput.focus();\n    </script>\n</body>\n</html>\"\"\"\n    return html_content\n\n@app.route('/chat', methods=['POST'])\ndef chat():\n    try:\n        user_input = request.json.get(\"message\", \"\").strip()\n        \n        if not user_input:\n            return jsonify({\"response\": \"Kuch toh bolo yaar!\"})\n        \n        # Find relevant context\n        context = find_relevant_context(user_input)\n        \n        # Generate response\n        ai_response = query_gemini_model(user_input, context)\n        \n        return jsonify({\"response\": ai_response})\n        \n    except Exception as e:\n        print(f\"Error in chat endpoint: {e}\")\n        return jsonify({\"response\": \"Something went wrong. Ask this on sports update group.\"})\n\n@app.route('/health', methods=['GET'])\ndef health():\n    return jsonify({\"status\": \"ok\", \"message\": \"SPIT SportsCom Bot is running!\"})\n\n# For local development\nif __name__ == '__main__':\n    print(\"Starting SPIT SportsCom Bot...\")\n    app.run(debug=True, host='0.0.0.0', port=5000)","size_bytes":17062},"VERCEL_FIX.md":{"content":"# Fix Vercel Deployment - 500 Error\n\n## Problem\nGetting 500 errors and \"Something went wrong! Ask this on sports update group\" message when chatting with bot on Vercel.\n\n## Root Cause\nGEMINI_API_KEY environment variable is not set in Vercel.\n\n## Solution (3 Simple Steps)\n\n### 1. Go to Vercel Dashboard\n- Open your Vercel project\n- Click on \"Settings\" tab\n\n### 2. Add Environment Variable\n- Go to \"Environment Variables\" section\n- Click \"Add New\"\n- Add:\n  - **Key**: `GEMINI_API_KEY`\n  - **Value**: Your Gemini API key (get one from https://aistudio.google.com/apikey)\n- Select all environments (Production, Preview, Development)\n- Click \"Save\"\n\n### 3. Redeploy\n- Go to \"Deployments\" tab\n- Click the 3 dots (...) on the latest deployment\n- Click \"Redeploy\"\n- Wait for deployment to complete\n\n## Verification\nAfter redeployment:\n1. Visit your Vercel URL\n2. Try chatting with the bot\n3. Should work without 500 errors\n\n## Additional Optional Variables\nYou can also add (but these have defaults):\n- `GEMINI_MODEL`: gemini-2.5-flash\n- `API_TEMPERATURE`: 0.3\n- `API_MAX_TOKENS`: 500\n\n---\n\n**That's it!** Your bot should work perfectly on Vercel now.\n","size_bytes":1145},"bot.py":{"content":"from pathlib import Path\nimport os\n\nfrom dotenv import load_dotenv\nload_dotenv()\nfrom google import genai\nfrom google.genai.types import GenerateContentConfig\n\nimport re, random\n\n\nclass SportsBot:\n    def __init__(self, context_file=\"context.txt\"):\n        path = Path(context_file)\n        if not path.exists():\n            raise FileNotFoundError(f\"Context file not found: {context_file}\")\n        self.context = path.read_text(encoding=\"utf-8\")\n        self.client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n        self.model = os.getenv(\"GEMINI_MODEL\", \"gemini-2.5-flash\")\n        self.temperature = float(os.getenv(\"API_TEMPERATURE\", \"0.3\"))\n        self.max_tokens = int(os.getenv(\"API_MAX_TOKENS\", \"500\"))\n        self.referer = os.getenv(\"HTTP_REFERER\", \"https://sports-committee-bot.com\")\n        self.system_rules = (\n            \"You are a knowledgeable sports assistant. Use the knowledge below to answer.\\n\"\n            \"Be clear and concise; think like a senior student member of the sports committee.\\n\"\n            \"If the user message contains any sort of profanity or abusive or improper language, reply exactly:\\n\"\n            \"\\\"Please use proper language.\\\"\\n\"\n            \"If user message is a greeting/pleasantry/small-talk (e.g. 'hi', 'hello', 'how are you', 'thanks', 'bye'), \"\n            \"reply naturally in 1 short line and DO NOT use any knowledge provided.\\n\"\n            \"If any other committee is mentioned, like Finance and Economics Club(FEC), Entrepreneurship Cell(E-Cell), Computer Society of India(CSI), Rotaract Club(RC), Drone Research Club(DRC), IETE, IEEE, ASCES, FACE, FETS, Speaker's club or SPCG, \"\n            \"redirect the conversation to Sports committee.\\n\"\n            \"If the user compares Sports committee with other committees, emphasize why Sports committee is the best.\\n\"\n            \"Make some witty, non-offensive, humorous remarks about the other committees Make sure it is NOT offensive or rude.\\n\"\n            \"When responding to such messages, do NOT mention their names, just refer to them as 'other committees' or 'they' or 'them'.\\n\"\n            \"Do not tolerate any negative comments about Sports committee or any other committee. If someone badmouths any committee, explain how every committee is different, but no committee is bad.\\n\"\n            \"Solve doubts of new students. Keep output simple text.\\n\"\n            \"For actual questions: Do not add info beyond the knowledge provided.\\n\"\n            \"If you don't know the answer, reply exactly: \\\"Ask this on sports update group\\\".\\n\"\n            \"If the question involves dates and dates aren't in the knowledge, reply exactly:\\n\"\n            \"\\\"Seniors will post the final dates on official class groups.\\\"\\n\"\n            \"STRICTLY DO NOT mention any knowledge base or context.\"\n            \"# ACCEPT ANSWERS IN HINGLISH IF THE QUESTION IS IN HINGLISH.\\n\"\n            \"IF THE QUESTION IS IN HINGLISH, ANSWER IN HINGLISH.\"\n        )\n        \n        self._small_talk_regexes = [\n            re.compile(r\"^\\s*(hi|hello|hey|yo|hola|namaste)\\s*[!.]*$\", re.I),\n            re.compile(r\"^\\s*(good\\s*(morning|afternoon|evening|night))\\s*[!.]*$\", re.I),\n            re.compile(r\"^\\s*(how\\s*are\\s*you|hru|how'?s\\s*it\\s*going)\\s*\\??\\s*$\", re.I),\n            re.compile(r\"^\\s*(thanks|thank\\s*you|ty|thx)\\s*[!.]*$\", re.I),\n            re.compile(r\"^\\s*(ok|okay|cool|nice)\\s*[!.]*$\", re.I),\n            re.compile(r\"^\\s*(bye|goodbye|see\\s*ya|see\\s*you)\\s*[!.]*$\", re.I),\n        ]\n        \n    def _is_small_talk(self, message: str) -> bool:\n        return any(rx.match(message) for rx in self._small_talk_regexes)\n    \n    def _small_talk_reply(self, msg: str) -> str:\n        m = msg.lower().strip()\n        if any(w in m for w in [\"hi\", \"hello\", \"hey\", \"yo\", \"hola\", \"namaste\", \"good morning\", \"good afternoon\", \"good evening\"]):\n            return random.choice([\"Hey! üëã\", \"Hello! üëã\", \"Hi! üëã\"])\n        if \"how are you\" in m or \"hru\" in m or \"how's it going\" in m:\n            return random.choice([\"All good! How can I help with sports info?\", \"Doing great!! What do you need help with?\"])\n        if \"thanks\" in m or \"thank you\" in m or \"ty\" in m or \"thx\" in m:\n            return random.choice([\"Anytime!\", \"You're welcome!\", \"Glad to help!\"])\n        if any(w in m for w in [\"ok\", \"okay\", \"cool\", \"nice\"]):\n            return random.choice([\"üëç\", \"Got it!\", \"Cool.\"])\n        if any(w in m for w in [\"bye\", \"goodbye\", \"see ya\", \"see you\"]):\n            return random.choice([\"Bye! üëã\", \"See you around!\", \"Take care!\"])\n        return \"Hey! How can I help with sports info?\"\n\n    def query_gemini(self, user_message: str) -> str:\n        prompt = f\"\"\"{self.system_rules}\n        Knowledge: {self.context}\n        \n        Question: {user_message}\n        \n        Please provide a clear, concise answer based on the knowledge provided.\"\"\"\n\n        response = self.client.models.generate_content(\n            model=self.model, \n            contents=prompt, \n            config=GenerateContentConfig(\n                temperature=self.temperature, \n                max_output_tokens=self.max_tokens)\n            )\n        \n        result = (response.text or \"\").strip()\n        if not result:\n            return \"Ask this on sports update group\"\n        return result\n\n    def get_response(self, user_input: str) -> str:\n        if self._is_small_talk(user_input):\n            return self._small_talk_reply(user_input)\n        return self.query_gemini(user_input)\n","size_bytes":5502},"main.py":{"content":"from fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import FileResponse, Response\nfrom fastapi.staticfiles import StaticFiles\nfrom pydantic import BaseModel\nimport os\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nfrom bot import SportsBot\n\nload_dotenv()\n\napp = FastAPI(\n    title=\"Sports Committee Chatbot API\", \n    version=\"1.0.0\",\n    description=\"AI-powered sports committee assistant API\"\n)\n\nallowed_origins = os.getenv(\"ALLOWED_ORIGINS\", \"*\")\nif allowed_origins == \"*\":\n    origins_list = [\"*\"]\nelse:\n    origins_list = [origin.strip() for origin in allowed_origins.split(\",\") if origin.strip()]\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=origins_list,\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\nbot = None\n\ndef get_bot():\n    \"\"\"Lazy initialization of bot for Vercel serverless compatibility\"\"\"\n    global bot\n    if bot is None:\n        try:\n            context_file = Path(__file__).parent / \"context.txt\"\n            bot = SportsBot(str(context_file))\n            print(f\"‚úÖ Sports bot initialized with {context_file}\")\n        except Exception as e:\n            print(f\"‚ùå Error initializing bot: {e}\")\n            raise HTTPException(status_code=500, detail=f\"Bot initialization failed: {str(e)}\")\n    return bot\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    \"\"\"Optional startup - will lazy-load if this doesn't run (Vercel compatibility)\"\"\"\n    try:\n        get_bot()\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Startup initialization skipped (will lazy-load): {e}\")\n\nclass ChatRequest(BaseModel):\n    message: str\n\nclass ChatResponse(BaseModel):\n    response: str\n\n@app.get(\"/\")\nasync def serve_frontend():\n    html_path = Path(__file__).parent / \"static\" / \"index.html\"\n    if html_path.exists():\n        with open(html_path, \"r\", encoding=\"utf-8\") as f:\n            html_content = f.read()\n        return Response(\n            content=html_content,\n            media_type=\"text/html\",\n            headers={\n                'Cache-Control': 'no-cache, no-store, must-revalidate',\n                'Pragma': 'no-cache',\n                'Expires': '0'\n            }\n        )\n    return {\"message\": \"Sports Committee Chatbot API is running!\"}\n\n@app.get(\"/health\")\nasync def health_check():\n    try:\n        current_bot = get_bot()\n        return {\"status\": \"healthy\", \"bot_ready\": current_bot is not None}\n    except Exception as e:\n        return {\"status\": \"unhealthy\", \"bot_ready\": False, \"error\": str(e)}\n\n@app.post(\"/keep-alive\")\nasync def keep_alive():\n    current_bot = get_bot()\n    \n    api_key = os.getenv(\"GEMINI_API_KEY\")\n    if not api_key:\n        raise HTTPException(\n            status_code=500, \n            detail=\"API key not found. Please set GEMINI_API_KEY environment variable.\"\n        )\n    \n    try:\n        response_text = current_bot.get_response(\"what is agility\")\n        return {\"status\": \"alive\", \"timestamp\": os.environ.get(\"TZ\", \"UTC\")}\n    except Exception as e:\n        print(f\"Error in keep-alive endpoint: {e}\")\n        raise HTTPException(status_code=500, detail=f\"Keep-alive failed: {str(e)}\")\n\n@app.post(\"/chat\", response_model=ChatResponse)\nasync def chat_endpoint(request: ChatRequest):\n    current_bot = get_bot()\n    \n    if not request.message.strip():\n        raise HTTPException(status_code=400, detail=\"Message cannot be empty\")\n    \n    api_key = os.getenv(\"GEMINI_API_KEY\")\n    if not api_key:\n        raise HTTPException(\n            status_code=500, \n            detail=\"API key not found. Please set GEMINI_API_KEY environment variable.\"\n        )\n    \n    try:\n        response_text = current_bot.get_response(request.message)\n        return ChatResponse(response=response_text)\n    except Exception as e:\n        error_msg = str(e)\n        print(f\"Error in chat endpoint: {error_msg}\")\n        raise HTTPException(status_code=500, detail=f\"Gemini API Error: {error_msg}\")\n\nif __name__ == \"__main__\":\n    import uvicorn\n    \n    host = os.getenv(\"HOST\", \"0.0.0.0\")\n    port = int(os.getenv(\"PORT\", \"5000\"))\n    reload = os.getenv(\"RELOAD\", \"false\").lower() == \"true\"\n    \n    print(f\"üöÄ Starting FastAPI server on {host}:{port}\")\n    print(f\"üìñ API Documentation: http://{host}:{port}/docs\")\n    print(f\"üîÑ Auto-reload: {reload}\")\n    print(f\"üåê Allowed origins: {origins_list}\")\n    \n    uvicorn.run(app, host=host, port=port, reload=reload)\n","size_bytes":4465},"replit.md":{"content":"# SPIT SportsCom Chatbot\n\n## Project Overview\nAn AI-powered chatbot designed for SPIT SportsCom committee to help students with sports-related queries. The bot responds in Hinglish and provides information about:\n- Agility Cup events and team formation\n- Spoorthi sports fest details\n- Committee selections and interviews\n- Sports trials and venues\n- General sports events and schedules\n\n## Current Status\n‚úÖ **FastAPI Backend Successfully Migrated** - Ready for production\n- Python 3.11 environment with FastAPI backend\n- Backend running on port 5000 with 0.0.0.0 binding\n- Dark theme frontend with red accents\n- Google Gemini AI integration with improved context handling\n- All endpoints tested and working perfectly\n\n## Recent Changes (October 01, 2025)\n- ‚úÖ **Successfully imported from GitHub and configured for Replit**\n- ‚úÖ Installed Python 3.11 environment\n- ‚úÖ Installed all required dependencies (FastAPI, Uvicorn, google-genai, etc.)\n- ‚úÖ Cleaned up requirements.txt (removed duplicates)\n- ‚úÖ Configured GEMINI_API_KEY secret in Replit\n- ‚úÖ Configured workflow to run FastAPI server on port 5000 with 0.0.0.0 binding\n- ‚úÖ Updated CORS settings to allow all origins for Replit proxy compatibility\n- ‚úÖ Tested all endpoints: /health, /chat - all working perfectly with Gemini AI\n- ‚úÖ Verified frontend displays correctly with dark theme and red accents\n- ‚úÖ Configured deployment settings for production (autoscale deployment)\n- ‚úÖ Server running successfully with bot initialized\n- ‚úÖ Chat functionality tested and working correctly\n\n## Project Architecture\n\n### Backend (FastAPI)\n- **Main app**: `main.py` - FastAPI application\n- **Bot logic**: `bot.py` - SportsBot class with Gemini AI\n- **Context**: `context.txt` - Sports knowledge base\n- **Configuration**: `.env` - Environment variables\n- **Port**: 5000 (frontend and API on same port)\n\n### Backend Endpoints\n- `GET /` - Serves the frontend HTML\n- `GET /health` - Health check endpoint\n- `POST /chat` - Chat endpoint for user queries\n- `POST /keep-alive` - Keep-alive endpoint for server monitoring\n\n### Frontend \n- **File**: `static/index.html` - Single-page application\n- **Theme**: Dark theme with red accents\n- **Features**: Real-time chat, typing indicators, smooth animations\n- **Integration**: Calls backend API on the same domain\n\n### AI Integration\n- **Platform**: Google Gemini AI (via google-genai SDK)\n- **Model**: gemini-2.5-flash\n- **Features**: \n  - Smart small talk detection\n  - Context-aware responses from knowledge base\n  - Profanity filtering\n  - Committee comparison handling\n  - Hinglish support\n\n### Key Features\n- **Small Talk**: Recognizes greetings and responds naturally\n- **Context Matching**: Uses knowledge base for accurate answers\n- **Fallback Responses**: Graceful handling when information unavailable\n- **Response Validation**: Ensures appropriate and accurate responses\n\n## Environment Variables\n- `GEMINI_API_KEY` - Google Gemini API key\n- `GEMINI_MODEL` - Model to use (default: gemini-2.5-flash)\n- `API_TEMPERATURE` - AI temperature setting (default: 0.3)\n- `API_MAX_TOKENS` - Max response tokens (default: 500)\n- `HOST` - Server host (0.0.0.0)\n- `PORT` - Server port (5000)\n- `RELOAD` - Auto-reload on code changes (true for development)\n- `ALLOWED_ORIGINS` - CORS allowed origins\n\n## Dependencies\n- fastapi==0.115.5 - Modern web framework\n- uvicorn==0.32.0 - ASGI server\n- pydantic==2.10.4 - Data validation\n- google-genai - Google Gemini AI SDK\n- python-dotenv==1.0.1 - Environment variable management\n- requests==2.32.3 - HTTP library\n\n## Workflow Configuration\n- **Command**: `uvicorn main:app --host 0.0.0.0 --port 5000 --reload`\n- **Port**: 5000\n- **Output**: Webview (frontend)\n- **Auto-reload**: Enabled for development\n\n## Technical Notes\n- FastAPI provides automatic API documentation at `/docs`\n- Bot uses text fingerprinting for context matching\n- Small talk detection uses regex patterns\n- Frontend served with cache-busting headers\n- CORS configured for multiple origins\n- All responses validated before sending\n\n## File Structure\n```\n‚îú‚îÄ‚îÄ main.py              # FastAPI application\n‚îú‚îÄ‚îÄ bot.py               # SportsBot class\n‚îú‚îÄ‚îÄ context.txt          # Knowledge base\n‚îú‚îÄ‚îÄ .env                 # Environment variables (not committed to Git)\n‚îú‚îÄ‚îÄ static/\n‚îÇ   ‚îî‚îÄ‚îÄ index.html       # Frontend application\n‚îú‚îÄ‚îÄ requirements.txt     # Python dependencies\n‚îú‚îÄ‚îÄ vercel.json          # Vercel deployment config\n‚îî‚îÄ‚îÄ replit.md            # This file\n```\n\n## Vercel Deployment\n\n### Important: Environment Variables Required!\nThe chatbot **will not work** on Vercel without setting environment variables. If you're getting 500 errors or \"Something went wrong!\" messages, follow these steps:\n\n### Deployment Steps:\n1. Push your code to GitHub\n2. Connect GitHub repo to Vercel\n3. **CRITICAL**: In Vercel project settings ‚Üí Environment Variables, add:\n   - `GEMINI_API_KEY` - Your Google Gemini API key (REQUIRED)\n   - `GEMINI_MODEL` - gemini-2.5-flash (optional, defaults to this)\n   - `API_TEMPERATURE` - 0.3 (optional)\n   - `API_MAX_TOKENS` - 500 (optional)\n4. Redeploy the project after adding environment variables\n\n### Troubleshooting Vercel Deployment:\n- **Error: 500 status / \"Something went wrong!\"** \n  ‚Üí GEMINI_API_KEY is not set in Vercel environment variables\n  ‚Üí Go to Project Settings ‚Üí Environment Variables ‚Üí Add GEMINI_API_KEY\n  ‚Üí Redeploy after adding the key\n  \n- **Error: \"Missing key inputs argument\"**\n  ‚Üí Same as above - add GEMINI_API_KEY to Vercel environment variables\n\n- **Bot not responding**\n  ‚Üí Check Vercel function logs for detailed error messages\n  ‚Üí Verify API key is valid and has Gemini API access\n","size_bytes":5723},"attached_assets/bot_1759338673895.py":{"content":"from pathlib import Path\nimport os\n\nfrom dotenv import load_dotenv\nload_dotenv()\nfrom google import genai\nfrom google.genai.types import GenerateContentConfig\n\nimport re, random\n\n\nclass SportsBot:\n    def __init__(self, context_file=\"context.txt\"):\n        # Load the whole context from file\n        path = Path(context_file)\n        if not path.exists():\n            raise FileNotFoundError(f\"Context file not found: {context_file}\")\n        self.context = path.read_text(encoding=\"utf-8\")\n        self.client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n        self.model=os.getenv(\"GEMINI_MODEL\", \"gemini-2.5-flash\")\n        self.temperature=float(os.getenv(\"API_TEMPERATURE\", \"0.3\"))\n        self.max_tokens=int(os.getenv(\"API_MAX_TOKENS\", \"500\"))\n        self.referer=os.getenv(\"HTTP_REFERER\", \"https://sports-committee-bot.com\")\n        self.system_rules = (\n            \"You are a knowledgeable sports assistant. Use the knowledge below to answer.\\n\"\n            \"Be clear and concise; think like a senior student member of the sports committee.\\n\"\n            \"If the user message contains any sort of profanity or abusive or improper language, reply exactly:\\n\"\n            \"\\\"Please use proper language.\\\"\\n\"\n            \"If user message is a greeting/pleasantry/small-talk (e.g. 'hi', 'hello', 'how are you', 'thanks', 'bye'), \"\n            \"reply naturally in 1 short line and DO NOT use any knowledge provided.\\n\"\n            \"If any other committee is mentioned, like Finance and Economics Club(FEC), Entrepreneurship Cell(E-Cell), Computer Society of India(CSI), Rotaract Club(RC), Drone Research Club(DRC), IETE, IEEE, ASCES, FACE, FETS, Speaker's club or SPCG, \"\n            \"redirect the conversation to Sports committee.\\n\"\n            \"If the user compares Sports committee with other committees, emphasize why Sports committee is the best.\\n\"\n            \"Make some witty, non-offensive, humorous remarks about the other committees Make sure it is NOT offensive or rude.\\n\"\n            \"When responding to such messages, do NOT mention their names, just refer to them as 'other committees' or 'they' or 'them'.\\n\"\n            \"Do not tolerate any negative comments about Sports committee or any other committee. If someone badmouths any committee, explain how every committee is different, but no committee is bad.\\n\"\n            \"Solve doubts of new students. Keep output simple text.\\n\"\n            \"For actual questions: Do not add info beyond the knowledge provided.\\n\"\n            \"If you don't know the answer, reply exactly: \\\"Ask this on sports update group\\\".\\n\"\n            \"If the question involves dates and dates aren't in the knowledge, reply exactly:\\n\"\n            \"\\\"Seniors will post the final dates on official class groups.\\\"\\n\"\n            \"STRICTLY DO NOT mention any knowledge base or context.\"\n            \"# ACCEPT ANSWERS IN HINGLISH IF THE QUESTION IS IN HINGLISH.\\n\"\n            \"IF THE QUESTION IS IN HINGLISH, ANSWER IN HINGLISH.\"\n            \n        )\n        \n        self._small_talk_regexes = [\n            re.compile(r\"^\\s*(hi|hello|hey|yo|hola|namaste)\\s*[!.]*$\", re.I),\n            re.compile(r\"^\\s*(good\\s*(morning|afternoon|evening|night))\\s*[!.]*$\", re.I),\n            re.compile(r\"^\\s*(how\\s*are\\s*you|hru|how'?s\\s*it\\s*going)\\s*\\??\\s*$\", re.I),\n            re.compile(r\"^\\s*(thanks|thank\\s*you|ty|thx)\\s*[!.]*$\", re.I),\n            re.compile(r\"^\\s*(ok|okay|cool|nice)\\s*[!.]*$\", re.I),\n            re.compile(r\"^\\s*(bye|goodbye|see\\s*ya|see\\s*you)\\s*[!.]*$\", re.I),\n        ]\n        \n    def _is_small_talk(self, message: str) -> bool:\n        return any(rx.match(message) for rx in self._small_talk_regexes)\n    \n    def _small_talk_reply(self, msg: str) -> str:\n        m = msg.lower().strip()\n        if any(w in m for w in [\"hi\", \"hello\", \"hey\", \"yo\", \"hola\", \"namaste\", \"good morning\", \"good afternoon\", \"good evening\"]):\n            return random.choice([\"Hey! üëã\", \"Hello! üëã\", \"Hi! üëã\"])\n        if \"how are you\" in m or \"hru\" in m or \"how's it going\" in m:\n            return random.choice([\"All good! How can I help with sports info?\", \"Doing great!! What do you need help with?\"])\n        if \"thanks\" in m or \"thank you\" in m or \"ty\" in m or \"thx\" in m:\n            return random.choice([\"Anytime!\", \"You're welcome!\", \"Glad to help!\"])\n        if any(w in m for w in [\"ok\", \"okay\", \"cool\", \"nice\"]):\n            return random.choice([\"üëç\", \"Got it!\", \"Cool.\"])\n        if any(w in m for w in [\"bye\", \"goodbye\", \"see ya\", \"see you\"]):\n            return random.choice([\"Bye! üëã\", \"See you around!\", \"Take care!\"])\n        return \"Hey! How can I help with sports info?\"\n\n    def query_gemini(self, user_message: str) -> str:\n        # Use provided config or defaults from environment\n\n        # headers = {\n        #     \"Authorization\": f\"Bearer {api_key}\",\n        #     \"HTTP-Referer\": referer,\n        #     \"Content-Type\": \"application/json\"\n        # }\n        \n        prompt = f\"\"\"{self.system_rules}\n        Knowledge: {self.context}\n        \n        Question: {user_message}\n        \n        Please provide a clear, concise answer citing the specific document source when possible.\"\"\"\n\n        # data = {\n        #     \"model\": model,  \n        #     \"temperature\": temperature,        # controls creativity (0 = strict, 1 = creative)\n        #     \"max_tokens\": max_tokens,         # controls max length of response\n        #     \"messages\": [\n        #         {\"role\": \"user\", \"content\": prompt}\n        #     ]\n        # }\n\n        response = self.client.models.generate_content(\n            model=self.model, \n            contents=prompt, \n            config=GenerateContentConfig(\n                temperature=self.temperature, \n                max_output_tokens=self.max_tokens)\n            )\n        return (response.text or \"\").strip()\n\n    def get_response(self, user_input: str) -> str:\n        if self._is_small_talk(user_input):\n            return self._small_talk_reply(user_input)\n        return self.query_gemini(user_input)\n\n\ndef main():\n    print(\"Initializing Sports Event Assistant Bot...\")\n    bot = SportsBot(\"context.txt\")\n\n    # Replace with your Gemini API key\n    # API_KEY = \"AIzaSyDXHa5g3QLhOMUZeioa_y2L4giVlyYDOBg\"\n    \n    print(\"\\nSports Event Assistant Bot Ready! (type 'quit' to exit)\")\n    print(\"-\" * 50)\n    \n    while True:\n        user_input = input(\"\\nYou: \").strip()\n        if user_input.lower() == 'quit':\n            break\n            \n        try:\n            response = bot.get_response(user_input)\n            print(f\"\\nQuestion: {user_input}\")   # üëà Show input first\n            print(f\"Answer: {response}\")        # üëà Then show output\n        except Exception as e:\n            print(f\"\\nError: {str(e)}\")\n\n\nif __name__ == \"__main__\":\n    main()","size_bytes":6802},"attached_assets/main_1759338673896.py":{"content":"from fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel\nimport os\nfrom dotenv import load_dotenv\nfrom bot import SportsBot\n\n# Load environment variables\nload_dotenv()\n\napp = FastAPI(\n    title=\"Sports Committee Chatbot API\", \n    version=\"1.0.0\",\n    description=\"AI-powered sports committee assistant API\"\n)\n\n# Get allowed origins from environment variable\nallowed_origins = os.getenv(\"ALLOWED_ORIGINS\", \"http://localhost:5173,http://localhost:3000,https://sports-spit-chatbot.vercel.app\")\norigins_list = [origin.strip() for origin in allowed_origins.split(\",\") if origin.strip()]\n\n# Configure CORS\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=origins_list,\n    allow_credentials=True,\n    allow_methods=[\"GET\", \"POST\"],\n    allow_headers=[\"*\"],\n)\n\n# Initialize the bot\nbot = None\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    global bot\n    try:\n        # Try to use processed_chunks.txt first, fallback to context.txt\n        context_file = \"processed_chunks.txt\" if os.path.exists(\"processed_chunks.txt\") else \"context.txt\"\n        bot = SportsBot(context_file)\n        print(f\"‚úÖ Sports bot initialized with {context_file}\")\n    except Exception as e:\n        print(f\"‚ùå Error initializing bot: {e}\")\n        raise\n\n# Pydantic models for request/response\nclass ChatRequest(BaseModel):\n    message: str\n\nclass ChatResponse(BaseModel):\n    response: str\n\n@app.get(\"/\")\nasync def root():\n    return {\"message\": \"Sports Committee Chatbot API is running!\"}\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\"status\": \"healthy\", \"bot_ready\": bot is not None}\n\n@app.post(\"/keep-alive\")\nasync def keep_alive():\n    \"\"\"Keep-alive endpoint for preventing server sleep on Render\"\"\"\n    if not bot:\n        raise HTTPException(status_code=500, detail=\"Bot not initialized\")\n    \n    # Check if bot has required API key (Gemini API)\n    api_key = os.getenv(\"GEMINI_API_KEY\")\n    if not api_key:\n        raise HTTPException(\n            status_code=500, \n            detail=\"API key not found. Please set GEMINI_API_KEY environment variable.\"\n        )\n    \n    try:\n        # Send a simple keep-alive query\n        response_text = bot.get_response(\"what is agility\")\n        return {\"status\": \"alive\", \"timestamp\": os.environ.get(\"TZ\", \"UTC\")}\n    except Exception as e:\n        print(f\"Error in keep-alive endpoint: {e}\")\n        raise HTTPException(status_code=500, detail=f\"Keep-alive failed: {str(e)}\")\n\n@app.post(\"/chat\", response_model=ChatResponse)\nasync def chat_endpoint(request: ChatRequest):\n    if not bot:\n        raise HTTPException(status_code=500, detail=\"Bot not initialized\")\n    \n    if not request.message.strip():\n        raise HTTPException(status_code=400, detail=\"Message cannot be empty\")\n    \n    # Check if bot has required API key (Gemini API)\n    api_key = os.getenv(\"GEMINI_API_KEY\")\n    if not api_key:\n        raise HTTPException(\n            status_code=500, \n            detail=\"API key not found. Please set GEMINI_API_KEY environment variable.\"\n        )\n    \n    try:\n        response_text = bot.get_response(request.message)\n        return ChatResponse(response=response_text)\n    except Exception as e:\n        print(f\"Error in chat endpoint: {e}\")\n        raise HTTPException(status_code=500, detail=f\"Error processing request: {str(e)}\")\n\nif __name__ == \"__main__\":\n    import uvicorn\n    \n    # Get server configuration from environment\n    host = os.getenv(\"HOST\", \"0.0.0.0\")\n    port = int(os.getenv(\"PORT\", \"8000\"))  # Render uses PORT env var\n    reload = os.getenv(\"RELOAD\", \"false\").lower() == \"true\"  # Disable reload in production\n    \n    print(f\"üöÄ Starting FastAPI server on {host}:{port}\")\n    print(f\"üìñ API Documentation: http://{host}:{port}/docs\")\n    print(f\"üîÑ Auto-reload: {reload}\")\n    print(f\"üåê Allowed origins: {origins_list}\")\n    \n    uvicorn.run(app, host=host, port=port, reload=reload)\n","size_bytes":3961},"attached_assets/App_1759347275060.jsx":{"content":"","size_bytes":0},"attached_assets/eslint.config_1759347209630.js":{"content":"","size_bytes":0},"attached_assets/index_1759347275061.css":{"content":"","size_bytes":0},"attached_assets/main_1759347275062.jsx":{"content":"","size_bytes":0},"attached_assets/tailwind.config_1759347209643.js":{"content":"","size_bytes":0}},"version":1}